---
layout: post
title: Automation and AI
---

The Upturn Automation and Quantified Society report summarized many key issues surrounding AI today. Among these were the tension between understandable and powerful algorithms, the accountability of algorithms, and our trust in computers. I found these three issues to bring up some of the most interesting and difficult questions.

This made me wornder what we value more, the ability to understand an algorithm or the performance of that algorithm. In some cases an automated process may be more successful when we don't need to audit the process. For example, some medical conditions can be diagnosed based on different risk factors. A machine learning algorithm that transforms these input factors in unexpected ways and weights each factor based on training data might not be clearly understandable to a human. Yet, this unintuitive algorithm might be the most accurate and successful at diagnosing a dangerous disease. Another automated process could be used for granting or denying visas. In cases like this, the ability to audit the automated decision is very important.

The article "The odd reality of life under China's all-seeing credit score system" is eye-opening and very concerning. This level of surveillance and data collection is a present day dystopia. This challenges the free way of life that I expect. This system creates very real consequences for small mistakes.


Based on the key issues above I generated different project ideas.

1. a calculator that makes mistakes
2. if we expect humans to be fallible, why not make computers look like humans
3. reverse mechanical turk - a human that's really controlled by a computer, maybe an online therapist
4. AR glasses that hide things from view
5. Our algorithms as objects - encode youtube/spotify/netflix recommendations as objects, do they belong to us? maybe 3d printed
6. A visualization of how companies automatically treat customers differently based on data



